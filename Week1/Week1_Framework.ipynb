{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Framework는 원하는 기능 구현에 집중하여 개발할 수 있도록 일정한 형태와 필요한 기능을 갖추고 있는 골격, 뼈대\n",
    "  - 이러한 뼈대 위에서 코드를 작성해 애플리케이션 개발\n",
    "  - 메모리 관리, 이벤트 루프 등의 공통된 부분은 프레임워크가 관리하며, 사용자는 프레임워크가 정해준 방식대로 클래스, 메소드 구현\n",
    "  - 예시\n",
    "    - Java 서버 개발에 사용되는 Spring\n",
    "    - Python 서버 개발에 사용되는 Django, Flask\n",
    "    - 안드로이드 앱 개발에 사용되는 Android\n",
    "    - 등...\n",
    "- Library는 소프트웨어 개발 시, 프로그램이 사용하는 비휘발성 자원의 모임\n",
    "  - 즉, 특정 기능을 모아둔 코드, 함수들의 집합\n",
    "  - 예시\n",
    "    - Python pip로 설치한 패키지/모듈(tensorflow, pytorch, pandas 등)\n",
    "- Framework와 Library의 차이점은 \"제어 흐름\"의 권한이 어디에 있는가에 있다.\n",
    "  - Library: 사용자가 코드의 흐름을 직접 제어해야 함\n",
    "    - 개발 시 필요한 기능이 있을 경우, 능동적으로 라이브러리를 호출해 사용\n",
    "  - Framework: 코드가 프레임워크게 의해 사용됨\n",
    "    - 코드는 프레임워크가 짜 놓은 틀에서 수동적으로 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝과 머신러닝의 관계: 딥러닝은 머신러닝의 부분집합이다.\n",
    "- 딥러닝과 머신러닝의 차이: 머신러닝은 자료 구조에 따라 다양한 형태를 지닌 방면, 딥러닝은 보통 전부 다 neural network로 구성\n",
    "- 특징\n",
    "  - 딥러닝은 머신러닝에 비해 parameter 수가 매우 많아 요구하는 데이터 수가 압도적으로 많음\n",
    "  - 딥러닝은 학습시간이 매우 오래걸리고 GPU를 통해 병렬 연산 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "# gpu 사용이 가능한 상태(cuda가 깔리고 nvidia gpu가 존재)하는 경우 device에 gpu할당, 아니면 cpu 할당\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(45) # seed 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(45) # cuda seed 고정\n",
    "print(device + \" is available\") # 위에서 지정한 device 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # 학습률 지정\n",
    "batch_size = 100 # 배치사이즈 지정\n",
    "num_classes = 10 # 클래스 수 지정\n",
    "epochs = 5 # 에포크 수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0295107364654541,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9912422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd15afec01d44599d62d6b31669db2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029398202896118164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 28881,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf3d98353c9401e98d11de278b21155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02428293228149414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1648877,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f94feadcdb442d5b27173e1613a3677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023556947708129883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4542,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681f858789b243ad9dcd4e2935c9f948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터셋 불러오기\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() \n",
    "    ])\n",
    ")\n",
    "\n",
    "# 평가 데이터셋 불러오기\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋을 데이터로더에 얹기\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# 데이터 shape 확인\n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class ConvNet(nn.Module):\n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # Convolution 연산 정의\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # Convolution 연산 정의\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) # Dropout 정의\n",
    "        self.mp = nn.MaxPool2d(2) # Max Pooling 정의\n",
    "        self.fc1 = nn.Linear(320,100) # Fully-Connected Layer 정의\n",
    "        self.fc2 = nn.Linear(100,10) # Fully-Connected Layer 정의\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "        x = F.relu(self.mp(self.conv1(x))) # convolution, max pooling 연산 후 ReLU 통과\n",
    "        x = F.relu(self.mp(self.conv2(x))) # convolution, max pooling 연산 후 ReLU 통과\n",
    "        x = self.drop2D(x) # Dropout 적용\n",
    "        x = x.view(x.size(0), -1) # 각 데이터를 1차원으로 만듦\n",
    "        x = self.fc1(x) # fully connected layer 통과\n",
    "        x = self.fc2(x) # fully connected layer 통과\n",
    "        return F.log_softmax(x) # log softmax 적용하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device) # 모델을 device에 할당\n",
    "criterion = nn.CrossEntropyLoss().to(device) # CrossEntropyLoss를 device에 할당\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # Adam을 device에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/d0l26xd500q6hk3ryfccwjy00000gn/T/ipykernel_1656/1780290213.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x) # log softmax 적용하여 반환\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1]  cost = 0.338579178\n",
      "[Epoch:    2]  cost = 0.114589147\n",
      "[Epoch:    3]  cost = 0.089051649\n",
      "[Epoch:    4]  cost = 0.076150313\n",
      "[Epoch:    5]  cost = 0.0688440949\n"
     ]
    }
   ],
   "source": [
    "# 학습 코드\n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device) # data를 device에 할당\n",
    "        target = target.to(device) # target을 device에 할당\n",
    "        optimizer.zero_grad() # 경사 초기화\n",
    "        hypothesis = model(data) # 예측값 출력\n",
    "        cost = criterion(hypothesis, target) # Loss 계산\n",
    "        cost.backward() # back propagation\n",
    "        optimizer.step() # parameter update\n",
    "        avg_cost += cost / len(train_loader) # 평균 비용 계산\n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/d0l26xd500q6hk3ryfccwjy00000gn/T/ipykernel_1656/1780290213.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x) # log softmax 적용하여 반환\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  98.48 %\n"
     ]
    }
   ],
   "source": [
    "# 평가 코드 작성\n",
    "model.eval() # 모델을 평가 모드로 수행(dropout 때문)\n",
    "with torch.no_grad(): # 경사를 계산하지 않음(학습을 하지 않기 때문)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device) # data를 device에 할당\n",
    "        target = target.to(device) # target을 device에 할당\n",
    "        out = model(data) # 예측값(score) 계산\n",
    "        preds = torch.max(out.data, 1)[1] # 예측 class 계산\n",
    "        total += len(target)\n",
    "        correct += (preds==target).sum().item() # 정답 개수 계산\n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%') # 정확도 출력\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 정규세션 들으시느라 고생 많으셨습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
