{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a817e26b",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "- Dacon,kaggle 코드 리뷰!\n",
    "- 본인이 직접 선택해서 앙상블 기법을 이용한 코드를 리뷰해주시면 됩니다!\n",
    "- Ex : Random forest, Xgboost 그외 모든 ensemble model\n",
    "- 채점 기준은 다음과 같습니다.\n",
    "    - 상세한 코드 리뷰 (앙상블 기법, 파라미터 튜닝 중점적으로)\n",
    "    - 코드 자체의 완성도 및 대회의 난이도\n",
    "- 앞서 배운 강의의 다양한 모델과 기법들을 활용해서 리뷰해주세요!\n",
    "- 코드 가져온 링크도 반드시 첨부해주세요! 채점할 때 사용합니다.\n",
    "- Baseline Model은 안됩니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fe28d",
   "metadata": {},
   "source": [
    "> #### 코드 출처\n",
    "> https://dacon.io/competitions/official/236035/codeshare/7544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc088dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4e4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "sample = pd.read_csv('./snp_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da0c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 437 entries, 0 to 436\n",
      "Data columns (total 20 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   father  437 non-null    int64 \n",
      " 1   mother  437 non-null    int64 \n",
      " 2   gender  437 non-null    int64 \n",
      " 3   trait   437 non-null    int64 \n",
      " 4   SNP_01  437 non-null    object\n",
      " 5   SNP_02  437 non-null    object\n",
      " 6   SNP_03  437 non-null    object\n",
      " 7   SNP_04  437 non-null    object\n",
      " 8   SNP_05  437 non-null    object\n",
      " 9   SNP_06  437 non-null    object\n",
      " 10  SNP_07  437 non-null    object\n",
      " 11  SNP_08  437 non-null    object\n",
      " 12  SNP_09  437 non-null    object\n",
      " 13  SNP_10  437 non-null    object\n",
      " 14  SNP_11  437 non-null    object\n",
      " 15  SNP_12  437 non-null    object\n",
      " 16  SNP_13  437 non-null    object\n",
      " 17  SNP_14  437 non-null    object\n",
      " 18  SNP_15  437 non-null    object\n",
      " 19  class   262 non-null    object\n",
      "dtypes: int64(4), object(16)\n",
      "memory usage: 68.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# 전처리를 위해 데이터 통합\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "df1 = df.drop(['id'],axis=1) # 필요 없는 열 제거\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5da225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 column을 category형 변수로 변환\n",
    "snp_col = [f'SNP_{str(x).zfill(2)}' for x in range(1,16)]\n",
    "for snp_col in df1.columns:\n",
    "    df1[snp_col] = df1[snp_col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2262f555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>gender</th>\n",
       "      <th>trait</th>\n",
       "      <th>SNP_01</th>\n",
       "      <th>SNP_02</th>\n",
       "      <th>SNP_03</th>\n",
       "      <th>SNP_04</th>\n",
       "      <th>SNP_05</th>\n",
       "      <th>SNP_06</th>\n",
       "      <th>...</th>\n",
       "      <th>SNP_14</th>\n",
       "      <th>SNP_15</th>\n",
       "      <th>class</th>\n",
       "      <th>chrom6</th>\n",
       "      <th>chrom9</th>\n",
       "      <th>cm_pos</th>\n",
       "      <th>name_ARS</th>\n",
       "      <th>name_BOV</th>\n",
       "      <th>name_HAP</th>\n",
       "      <th>name_BT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     father  mother  gender  trait  SNP_01  SNP_02  SNP_03  SNP_04  SNP_05  \\\n",
       "0         0       0       0      1       2       1       0       1       1   \n",
       "1         0       0       0      1       1       1       1       0       0   \n",
       "2         0       0       0      1       2       2       0       1       2   \n",
       "3         0       0       0      0       0       2       0       1       0   \n",
       "4         0       0       0      1       2       2       2       0       2   \n",
       "..      ...     ...     ...    ...     ...     ...     ...     ...     ...   \n",
       "432       0       0       0      1       1       2       2       0       1   \n",
       "433       0       0       0      1       2       0       0       0       1   \n",
       "434       0       0       0      1       2       0       0       0       1   \n",
       "435       0       0       0      1       1       2       1       1       2   \n",
       "436       0       0       0      1       2       2       2       1       1   \n",
       "\n",
       "     SNP_06  ...  SNP_14  SNP_15  class  chrom6    chrom9    cm_pos  name_ARS  \\\n",
       "0         0  ...       0       0      1   0.625  0.000000  0.461538       0.6   \n",
       "1         1  ...       0       0      2   0.500  1.000000  0.538462       0.4   \n",
       "2         2  ...       0       0      1   1.125  0.000000  0.615385       0.8   \n",
       "3         2  ...       0       2      0   1.125  1.333333  1.076923       1.4   \n",
       "4         0  ...       0       1      2   0.750  0.333333  0.615385       0.8   \n",
       "..      ...  ...     ...     ...    ...     ...       ...       ...       ...   \n",
       "432       1  ...       0       1     -1   1.000  0.000000  0.692308       1.2   \n",
       "433       1  ...       0       1     -1   0.250  0.333333  0.384615       0.0   \n",
       "434       1  ...       0       2     -1   0.250  0.333333  0.538462       0.2   \n",
       "435       2  ...       0       0     -1   1.125  0.000000  0.692308       1.0   \n",
       "436       0  ...       0       0     -1   1.125  0.000000  0.692308       1.4   \n",
       "\n",
       "     name_BOV  name_HAP   name_BT  \n",
       "0        0.75  0.000000  1.333333  \n",
       "1        0.50  0.333333  1.333333  \n",
       "2        1.25  0.000000  1.000000  \n",
       "3        1.00  1.333333  1.000000  \n",
       "4        0.75  0.000000  1.666667  \n",
       "..        ...       ...       ...  \n",
       "432      1.25  0.000000  1.000000  \n",
       "433      0.75  0.000000  1.333333  \n",
       "434      1.00  0.000000  1.666667  \n",
       "435      1.25  0.000000  1.000000  \n",
       "436      0.75  0.333333  1.333333  \n",
       "\n",
       "[437 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파생 변수 생성\n",
    "df1['chrom6'] = (df1['SNP_02']+df1['SNP_03']+df1['SNP_04']+df1['SNP_05']+df1['SNP_06']+df1['SNP_07']+df1['SNP_08']+df1['SNP_09'])/8\n",
    "df1['chrom9'] = (df1['SNP_12']+df1['SNP_13']+df1['SNP_14'])/3\n",
    "df1['cm_pos'] = (df1['SNP_03']+df1['SNP_04']+df1['SNP_05']+df1['SNP_06']+df1['SNP_07']+df1['SNP_08']+df1['SNP_09']\n",
    "                +df1['SNP_10']+df1['SNP_12']+df1['SNP_13']+df1['SNP_14']+df1['SNP_15'])/13\n",
    "df1['name_ARS'] = (df1['SNP_02']+df1['SNP_03']+df1['SNP_04']+df1['SNP_09']+df1['SNP_11'])/5\n",
    "df1['name_BOV'] = (df1['SNP_05']+df1['SNP_06']+df1['SNP_08']+df1['SNP_15'])/4\n",
    "df1['name_HAP'] = (df1['SNP_07']+df1['SNP_12']+df1['SNP_14'])/3\n",
    "df1['name_BT'] = (df1['SNP_01']+df1['SNP_10']+df1['SNP_13'])/3\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5a36acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trait</th>\n",
       "      <th>SNP_01</th>\n",
       "      <th>SNP_02</th>\n",
       "      <th>SNP_03</th>\n",
       "      <th>SNP_04</th>\n",
       "      <th>SNP_05</th>\n",
       "      <th>SNP_06</th>\n",
       "      <th>SNP_07</th>\n",
       "      <th>SNP_08</th>\n",
       "      <th>SNP_09</th>\n",
       "      <th>...</th>\n",
       "      <th>SNP_13</th>\n",
       "      <th>SNP_14</th>\n",
       "      <th>SNP_15</th>\n",
       "      <th>chrom6</th>\n",
       "      <th>chrom9</th>\n",
       "      <th>name_ARS</th>\n",
       "      <th>name_BOV</th>\n",
       "      <th>name_HAP</th>\n",
       "      <th>name_BT</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trait  SNP_01  SNP_02  SNP_03  SNP_04  SNP_05  SNP_06  SNP_07  SNP_08  \\\n",
       "0        1       2       1       0       1       1       0       0       2   \n",
       "1        1       1       1       1       0       0       1       0       1   \n",
       "2        1       2       2       0       1       2       2       0       1   \n",
       "3        0       0       2       0       1       0       2       2       0   \n",
       "4        1       2       2       2       0       2       0       0       0   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "257      1       1       1       0       1       2       1       0       1   \n",
       "258      1       2       0       1       0       0       1       1       1   \n",
       "259      0       1       2       0       1       0       1       2       1   \n",
       "260      0       0       2       0       1       0       2       2       0   \n",
       "261      1       2       1       1       2       2       1       0       0   \n",
       "\n",
       "     SNP_09  ...  SNP_13  SNP_14  SNP_15  chrom6    chrom9  name_ARS  \\\n",
       "0         0  ...       0       0       0   0.625  0.000000       0.6   \n",
       "1         0  ...       2       0       0   0.500  1.000000       0.4   \n",
       "2         1  ...       0       0       0   1.125  0.000000       0.8   \n",
       "3         2  ...       2       0       2   1.125  1.333333       1.4   \n",
       "4         0  ...       1       0       1   0.750  0.333333       0.8   \n",
       "..      ...  ...     ...     ...     ...     ...       ...       ...   \n",
       "257       0  ...       0       0       0   0.750  0.333333       0.6   \n",
       "258       0  ...       1       0       1   0.500  0.333333       0.4   \n",
       "259       1  ...       2       1       2   1.000  1.666667       1.2   \n",
       "260       1  ...       2       1       2   1.000  1.333333       1.0   \n",
       "261       0  ...       2       0       1   0.875  0.666667       0.8   \n",
       "\n",
       "     name_BOV  name_HAP   name_BT  class  \n",
       "0        0.75  0.000000  1.333333      1  \n",
       "1        0.50  0.333333  1.333333      2  \n",
       "2        1.25  0.000000  1.000000      1  \n",
       "3        1.00  1.333333  1.000000      0  \n",
       "4        0.75  0.000000  1.666667      2  \n",
       "..        ...       ...       ...    ...  \n",
       "257      1.00  0.333333  1.000000      1  \n",
       "258      0.75  0.333333  1.333333      2  \n",
       "259      1.00  1.666667  1.000000      0  \n",
       "260      1.00  1.333333  1.000000      0  \n",
       "261      1.00  0.000000  2.000000      1  \n",
       "\n",
       "[262 rows x 23 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 특정 feature 선택\n",
    "dfx = df1[['trait','SNP_01','SNP_02','SNP_03','SNP_04','SNP_05','SNP_06','SNP_07',\n",
    "          'SNP_08','SNP_09','SNP_10','SNP_11','SNP_12','SNP_13',\n",
    "          'SNP_14','SNP_15','chrom6','chrom9','name_ARS','name_BOV','name_HAP','name_BT']]\n",
    "dfy = df1['class']\n",
    "\n",
    "xtrain = dfx.iloc[:len(train)]\n",
    "xsubmission = dfx.iloc[len(train):]\n",
    "# label encoding 수행\n",
    "class_le = preprocessing.LabelEncoder()\n",
    "ytrain = class_le.fit_transform(train['class'])\n",
    "xtrain['class'] = ytrain\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "19f39334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_82836 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82836_row0_col0, #T_82836_row0_col2, #T_82836_row1_col0, #T_82836_row1_col1, #T_82836_row1_col2, #T_82836_row1_col3, #T_82836_row1_col4, #T_82836_row1_col5, #T_82836_row1_col6, #T_82836_row1_col7, #T_82836_row2_col0, #T_82836_row2_col1, #T_82836_row2_col2, #T_82836_row2_col3, #T_82836_row2_col4, #T_82836_row2_col5, #T_82836_row2_col6, #T_82836_row2_col7, #T_82836_row3_col0, #T_82836_row3_col1, #T_82836_row3_col2, #T_82836_row3_col3, #T_82836_row3_col4, #T_82836_row3_col5, #T_82836_row3_col6, #T_82836_row3_col7, #T_82836_row4_col0, #T_82836_row4_col1, #T_82836_row4_col2, #T_82836_row4_col3, #T_82836_row4_col4, #T_82836_row4_col5, #T_82836_row4_col6, #T_82836_row4_col7, #T_82836_row5_col0, #T_82836_row5_col1, #T_82836_row5_col3, #T_82836_row5_col4, #T_82836_row5_col5, #T_82836_row5_col6, #T_82836_row5_col7, #T_82836_row6_col0, #T_82836_row6_col1, #T_82836_row6_col2, #T_82836_row6_col3, #T_82836_row6_col4, #T_82836_row6_col5, #T_82836_row6_col6, #T_82836_row6_col7, #T_82836_row7_col0, #T_82836_row7_col1, #T_82836_row7_col2, #T_82836_row7_col3, #T_82836_row7_col4, #T_82836_row7_col5, #T_82836_row7_col6, #T_82836_row7_col7, #T_82836_row8_col0, #T_82836_row8_col1, #T_82836_row8_col2, #T_82836_row8_col3, #T_82836_row8_col4, #T_82836_row8_col5, #T_82836_row8_col6, #T_82836_row8_col7, #T_82836_row9_col0, #T_82836_row9_col1, #T_82836_row9_col2, #T_82836_row9_col3, #T_82836_row9_col4, #T_82836_row9_col5, #T_82836_row9_col6, #T_82836_row9_col7, #T_82836_row10_col0, #T_82836_row10_col1, #T_82836_row10_col2, #T_82836_row10_col3, #T_82836_row10_col4, #T_82836_row10_col5, #T_82836_row10_col6, #T_82836_row10_col7, #T_82836_row11_col0, #T_82836_row11_col1, #T_82836_row11_col2, #T_82836_row11_col3, #T_82836_row11_col4, #T_82836_row11_col5, #T_82836_row11_col6, #T_82836_row11_col7, #T_82836_row12_col0, #T_82836_row12_col1, #T_82836_row12_col2, #T_82836_row12_col3, #T_82836_row12_col4, #T_82836_row12_col5, #T_82836_row12_col6, #T_82836_row12_col7, #T_82836_row13_col0, #T_82836_row13_col1, #T_82836_row13_col2, #T_82836_row13_col3, #T_82836_row13_col4, #T_82836_row13_col5, #T_82836_row13_col6, #T_82836_row13_col7, #T_82836_row14_col0, #T_82836_row14_col1, #T_82836_row14_col2, #T_82836_row14_col3, #T_82836_row14_col4, #T_82836_row14_col5, #T_82836_row14_col6, #T_82836_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82836_row0_col1, #T_82836_row0_col3, #T_82836_row0_col4, #T_82836_row0_col5, #T_82836_row0_col6, #T_82836_row0_col7, #T_82836_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_82836_row0_col8, #T_82836_row2_col8, #T_82836_row3_col8, #T_82836_row4_col8, #T_82836_row5_col8, #T_82836_row6_col8, #T_82836_row7_col8, #T_82836_row8_col8, #T_82836_row10_col8, #T_82836_row12_col8, #T_82836_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_82836_row1_col8, #T_82836_row9_col8, #T_82836_row11_col8, #T_82836_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_82836\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_82836_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_82836_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_82836_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_82836_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_82836_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_82836_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_82836_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_82836_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_82836_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_82836_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_82836_row0_col1\" class=\"data row0 col1\" >0.9566</td>\n",
       "      <td id=\"T_82836_row0_col2\" class=\"data row0 col2\" >0.9855</td>\n",
       "      <td id=\"T_82836_row0_col3\" class=\"data row0 col3\" >0.9586</td>\n",
       "      <td id=\"T_82836_row0_col4\" class=\"data row0 col4\" >0.9581</td>\n",
       "      <td id=\"T_82836_row0_col5\" class=\"data row0 col5\" >0.9566</td>\n",
       "      <td id=\"T_82836_row0_col6\" class=\"data row0 col6\" >0.9328</td>\n",
       "      <td id=\"T_82836_row0_col7\" class=\"data row0 col7\" >0.9337</td>\n",
       "      <td id=\"T_82836_row0_col8\" class=\"data row0 col8\" >0.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row1\" class=\"row_heading level0 row1\" >lda</th>\n",
       "      <td id=\"T_82836_row1_col0\" class=\"data row1 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_82836_row1_col1\" class=\"data row1 col1\" >0.9514</td>\n",
       "      <td id=\"T_82836_row1_col2\" class=\"data row1 col2\" >0.9897</td>\n",
       "      <td id=\"T_82836_row1_col3\" class=\"data row1 col3\" >0.9553</td>\n",
       "      <td id=\"T_82836_row1_col4\" class=\"data row1 col4\" >0.9544</td>\n",
       "      <td id=\"T_82836_row1_col5\" class=\"data row1 col5\" >0.9512</td>\n",
       "      <td id=\"T_82836_row1_col6\" class=\"data row1 col6\" >0.9249</td>\n",
       "      <td id=\"T_82836_row1_col7\" class=\"data row1 col7\" >0.9267</td>\n",
       "      <td id=\"T_82836_row1_col8\" class=\"data row1 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row2\" class=\"row_heading level0 row2\" >et</th>\n",
       "      <td id=\"T_82836_row2_col0\" class=\"data row2 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_82836_row2_col1\" class=\"data row2 col1\" >0.9512</td>\n",
       "      <td id=\"T_82836_row2_col2\" class=\"data row2 col2\" >0.9875</td>\n",
       "      <td id=\"T_82836_row2_col3\" class=\"data row2 col3\" >0.9519</td>\n",
       "      <td id=\"T_82836_row2_col4\" class=\"data row2 col4\" >0.9523</td>\n",
       "      <td id=\"T_82836_row2_col5\" class=\"data row2 col5\" >0.9511</td>\n",
       "      <td id=\"T_82836_row2_col6\" class=\"data row2 col6\" >0.9243</td>\n",
       "      <td id=\"T_82836_row2_col7\" class=\"data row2 col7\" >0.9250</td>\n",
       "      <td id=\"T_82836_row2_col8\" class=\"data row2 col8\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "      <td id=\"T_82836_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_82836_row3_col1\" class=\"data row3 col1\" >0.9456</td>\n",
       "      <td id=\"T_82836_row3_col2\" class=\"data row3 col2\" >0.9879</td>\n",
       "      <td id=\"T_82836_row3_col3\" class=\"data row3 col3\" >0.9495</td>\n",
       "      <td id=\"T_82836_row3_col4\" class=\"data row3 col4\" >0.9485</td>\n",
       "      <td id=\"T_82836_row3_col5\" class=\"data row3 col5\" >0.9458</td>\n",
       "      <td id=\"T_82836_row3_col6\" class=\"data row3 col6\" >0.9162</td>\n",
       "      <td id=\"T_82836_row3_col7\" class=\"data row3 col7\" >0.9175</td>\n",
       "      <td id=\"T_82836_row3_col8\" class=\"data row3 col8\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row4\" class=\"row_heading level0 row4\" >lightgbm</th>\n",
       "      <td id=\"T_82836_row4_col0\" class=\"data row4 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_82836_row4_col1\" class=\"data row4 col1\" >0.9455</td>\n",
       "      <td id=\"T_82836_row4_col2\" class=\"data row4 col2\" >0.9901</td>\n",
       "      <td id=\"T_82836_row4_col3\" class=\"data row4 col3\" >0.9505</td>\n",
       "      <td id=\"T_82836_row4_col4\" class=\"data row4 col4\" >0.9479</td>\n",
       "      <td id=\"T_82836_row4_col5\" class=\"data row4 col5\" >0.9456</td>\n",
       "      <td id=\"T_82836_row4_col6\" class=\"data row4 col6\" >0.9157</td>\n",
       "      <td id=\"T_82836_row4_col7\" class=\"data row4 col7\" >0.9169</td>\n",
       "      <td id=\"T_82836_row4_col8\" class=\"data row4 col8\" >0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_82836_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_82836_row5_col1\" class=\"data row5 col1\" >0.9405</td>\n",
       "      <td id=\"T_82836_row5_col2\" class=\"data row5 col2\" >0.9922</td>\n",
       "      <td id=\"T_82836_row5_col3\" class=\"data row5 col3\" >0.9414</td>\n",
       "      <td id=\"T_82836_row5_col4\" class=\"data row5 col4\" >0.9406</td>\n",
       "      <td id=\"T_82836_row5_col5\" class=\"data row5 col5\" >0.9404</td>\n",
       "      <td id=\"T_82836_row5_col6\" class=\"data row5 col6\" >0.9077</td>\n",
       "      <td id=\"T_82836_row5_col7\" class=\"data row5 col7\" >0.9079</td>\n",
       "      <td id=\"T_82836_row5_col8\" class=\"data row5 col8\" >0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row6\" class=\"row_heading level0 row6\" >knn</th>\n",
       "      <td id=\"T_82836_row6_col0\" class=\"data row6 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_82836_row6_col1\" class=\"data row6 col1\" >0.9402</td>\n",
       "      <td id=\"T_82836_row6_col2\" class=\"data row6 col2\" >0.9920</td>\n",
       "      <td id=\"T_82836_row6_col3\" class=\"data row6 col3\" >0.9386</td>\n",
       "      <td id=\"T_82836_row6_col4\" class=\"data row6 col4\" >0.9410</td>\n",
       "      <td id=\"T_82836_row6_col5\" class=\"data row6 col5\" >0.9400</td>\n",
       "      <td id=\"T_82836_row6_col6\" class=\"data row6 col6\" >0.9071</td>\n",
       "      <td id=\"T_82836_row6_col7\" class=\"data row6 col7\" >0.9078</td>\n",
       "      <td id=\"T_82836_row6_col8\" class=\"data row6 col8\" >0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n",
       "      <td id=\"T_82836_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_82836_row7_col1\" class=\"data row7 col1\" >0.9348</td>\n",
       "      <td id=\"T_82836_row7_col2\" class=\"data row7 col2\" >0.9883</td>\n",
       "      <td id=\"T_82836_row7_col3\" class=\"data row7 col3\" >0.9369</td>\n",
       "      <td id=\"T_82836_row7_col4\" class=\"data row7 col4\" >0.9355</td>\n",
       "      <td id=\"T_82836_row7_col5\" class=\"data row7 col5\" >0.9348</td>\n",
       "      <td id=\"T_82836_row7_col6\" class=\"data row7 col6\" >0.8992</td>\n",
       "      <td id=\"T_82836_row7_col7\" class=\"data row7 col7\" >0.8996</td>\n",
       "      <td id=\"T_82836_row7_col8\" class=\"data row7 col8\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "      <td id=\"T_82836_row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_82836_row8_col1\" class=\"data row8 col1\" >0.9351</td>\n",
       "      <td id=\"T_82836_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_82836_row8_col3\" class=\"data row8 col3\" >0.9353</td>\n",
       "      <td id=\"T_82836_row8_col4\" class=\"data row8 col4\" >0.9361</td>\n",
       "      <td id=\"T_82836_row8_col5\" class=\"data row8 col5\" >0.9345</td>\n",
       "      <td id=\"T_82836_row8_col6\" class=\"data row8 col6\" >0.8990</td>\n",
       "      <td id=\"T_82836_row8_col7\" class=\"data row8 col7\" >0.9002</td>\n",
       "      <td id=\"T_82836_row8_col8\" class=\"data row8 col8\" >0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row9\" class=\"row_heading level0 row9\" >svm</th>\n",
       "      <td id=\"T_82836_row9_col0\" class=\"data row9 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_82836_row9_col1\" class=\"data row9 col1\" >0.9078</td>\n",
       "      <td id=\"T_82836_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_82836_row9_col3\" class=\"data row9 col3\" >0.9148</td>\n",
       "      <td id=\"T_82836_row9_col4\" class=\"data row9 col4\" >0.9124</td>\n",
       "      <td id=\"T_82836_row9_col5\" class=\"data row9 col5\" >0.9080</td>\n",
       "      <td id=\"T_82836_row9_col6\" class=\"data row9 col6\" >0.8584</td>\n",
       "      <td id=\"T_82836_row9_col7\" class=\"data row9 col7\" >0.8605</td>\n",
       "      <td id=\"T_82836_row9_col8\" class=\"data row9 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_82836_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_82836_row10_col1\" class=\"data row10 col1\" >0.8959</td>\n",
       "      <td id=\"T_82836_row10_col2\" class=\"data row10 col2\" >0.9890</td>\n",
       "      <td id=\"T_82836_row10_col3\" class=\"data row10 col3\" >0.8859</td>\n",
       "      <td id=\"T_82836_row10_col4\" class=\"data row10 col4\" >0.9073</td>\n",
       "      <td id=\"T_82836_row10_col5\" class=\"data row10 col5\" >0.8912</td>\n",
       "      <td id=\"T_82836_row10_col6\" class=\"data row10 col6\" >0.8356</td>\n",
       "      <td id=\"T_82836_row10_col7\" class=\"data row10 col7\" >0.8451</td>\n",
       "      <td id=\"T_82836_row10_col8\" class=\"data row10 col8\" >0.2460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_82836_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_82836_row11_col1\" class=\"data row11 col1\" >0.8797</td>\n",
       "      <td id=\"T_82836_row11_col2\" class=\"data row11 col2\" >0.9032</td>\n",
       "      <td id=\"T_82836_row11_col3\" class=\"data row11 col3\" >0.8840</td>\n",
       "      <td id=\"T_82836_row11_col4\" class=\"data row11 col4\" >0.8845</td>\n",
       "      <td id=\"T_82836_row11_col5\" class=\"data row11 col5\" >0.8796</td>\n",
       "      <td id=\"T_82836_row11_col6\" class=\"data row11 col6\" >0.8134</td>\n",
       "      <td id=\"T_82836_row11_col7\" class=\"data row11 col7\" >0.8161</td>\n",
       "      <td id=\"T_82836_row11_col8\" class=\"data row11 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row12\" class=\"row_heading level0 row12\" >ada</th>\n",
       "      <td id=\"T_82836_row12_col0\" class=\"data row12 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_82836_row12_col1\" class=\"data row12 col1\" >0.8686</td>\n",
       "      <td id=\"T_82836_row12_col2\" class=\"data row12 col2\" >0.9684</td>\n",
       "      <td id=\"T_82836_row12_col3\" class=\"data row12 col3\" >0.8921</td>\n",
       "      <td id=\"T_82836_row12_col4\" class=\"data row12 col4\" >0.8917</td>\n",
       "      <td id=\"T_82836_row12_col5\" class=\"data row12 col5\" >0.8699</td>\n",
       "      <td id=\"T_82836_row12_col6\" class=\"data row12 col6\" >0.8010</td>\n",
       "      <td id=\"T_82836_row12_col7\" class=\"data row12 col7\" >0.8122</td>\n",
       "      <td id=\"T_82836_row12_col8\" class=\"data row12 col8\" >0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_82836_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_82836_row13_col1\" class=\"data row13 col1\" >0.4536</td>\n",
       "      <td id=\"T_82836_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_82836_row13_col3\" class=\"data row13 col3\" >0.3333</td>\n",
       "      <td id=\"T_82836_row13_col4\" class=\"data row13 col4\" >0.2059</td>\n",
       "      <td id=\"T_82836_row13_col5\" class=\"data row13 col5\" >0.2832</td>\n",
       "      <td id=\"T_82836_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_82836_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_82836_row13_col8\" class=\"data row13 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82836_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_82836_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_82836_row14_col1\" class=\"data row14 col1\" >0.2677</td>\n",
       "      <td id=\"T_82836_row14_col2\" class=\"data row14 col2\" >0.0000</td>\n",
       "      <td id=\"T_82836_row14_col3\" class=\"data row14 col3\" >0.3333</td>\n",
       "      <td id=\"T_82836_row14_col4\" class=\"data row14 col4\" >0.0718</td>\n",
       "      <td id=\"T_82836_row14_col5\" class=\"data row14 col5\" >0.1132</td>\n",
       "      <td id=\"T_82836_row14_col6\" class=\"data row14 col6\" >0.0000</td>\n",
       "      <td id=\"T_82836_row14_col7\" class=\"data row14 col7\" >0.0000</td>\n",
       "      <td id=\"T_82836_row14_col8\" class=\"data row14 col8\" >0.0080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe2e868e4f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pycaret 기반 model comparision\n",
    "from pycaret.classification import * \n",
    "clf = setup(data=xtrain, target='class'\n",
    "            ,session_id=42)\n",
    "models = compare_models(fold=5, round=4, sort='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3e5b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0ac35_row10_col0, #T_0ac35_row10_col1, #T_0ac35_row10_col2, #T_0ac35_row10_col3, #T_0ac35_row10_col4, #T_0ac35_row10_col5, #T_0ac35_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0ac35\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0ac35_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_0ac35_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_0ac35_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_0ac35_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_0ac35_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_0ac35_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_0ac35_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0ac35_row0_col0\" class=\"data row0 col0\" >0.9474</td>\n",
       "      <td id=\"T_0ac35_row0_col1\" class=\"data row0 col1\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row0_col2\" class=\"data row0 col2\" >0.9444</td>\n",
       "      <td id=\"T_0ac35_row0_col3\" class=\"data row0 col3\" >0.9532</td>\n",
       "      <td id=\"T_0ac35_row0_col4\" class=\"data row0 col4\" >0.9465</td>\n",
       "      <td id=\"T_0ac35_row0_col5\" class=\"data row0 col5\" >0.9188</td>\n",
       "      <td id=\"T_0ac35_row0_col6\" class=\"data row0 col6\" >0.9228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0ac35_row1_col0\" class=\"data row1 col0\" >0.8947</td>\n",
       "      <td id=\"T_0ac35_row1_col1\" class=\"data row1 col1\" >0.9383</td>\n",
       "      <td id=\"T_0ac35_row1_col2\" class=\"data row1 col2\" >0.8963</td>\n",
       "      <td id=\"T_0ac35_row1_col3\" class=\"data row1 col3\" >0.8947</td>\n",
       "      <td id=\"T_0ac35_row1_col4\" class=\"data row1 col4\" >0.8947</td>\n",
       "      <td id=\"T_0ac35_row1_col5\" class=\"data row1 col5\" >0.8348</td>\n",
       "      <td id=\"T_0ac35_row1_col6\" class=\"data row1 col6\" >0.8348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0ac35_row2_col0\" class=\"data row2 col0\" >0.9474</td>\n",
       "      <td id=\"T_0ac35_row2_col1\" class=\"data row2 col1\" >0.9910</td>\n",
       "      <td id=\"T_0ac35_row2_col2\" class=\"data row2 col2\" >0.9630</td>\n",
       "      <td id=\"T_0ac35_row2_col3\" class=\"data row2 col3\" >0.9561</td>\n",
       "      <td id=\"T_0ac35_row2_col4\" class=\"data row2 col4\" >0.9482</td>\n",
       "      <td id=\"T_0ac35_row2_col5\" class=\"data row2 col5\" >0.9188</td>\n",
       "      <td id=\"T_0ac35_row2_col6\" class=\"data row2 col6\" >0.9228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0ac35_row3_col0\" class=\"data row3 col0\" >0.8889</td>\n",
       "      <td id=\"T_0ac35_row3_col1\" class=\"data row3 col1\" >0.9791</td>\n",
       "      <td id=\"T_0ac35_row3_col2\" class=\"data row3 col2\" >0.8963</td>\n",
       "      <td id=\"T_0ac35_row3_col3\" class=\"data row3 col3\" >0.8889</td>\n",
       "      <td id=\"T_0ac35_row3_col4\" class=\"data row3 col4\" >0.8889</td>\n",
       "      <td id=\"T_0ac35_row3_col5\" class=\"data row3 col5\" >0.8218</td>\n",
       "      <td id=\"T_0ac35_row3_col6\" class=\"data row3 col6\" >0.8218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0ac35_row4_col0\" class=\"data row4 col0\" >0.9444</td>\n",
       "      <td id=\"T_0ac35_row4_col1\" class=\"data row4 col1\" >0.9902</td>\n",
       "      <td id=\"T_0ac35_row4_col2\" class=\"data row4 col2\" >0.9583</td>\n",
       "      <td id=\"T_0ac35_row4_col3\" class=\"data row4 col3\" >0.9537</td>\n",
       "      <td id=\"T_0ac35_row4_col4\" class=\"data row4 col4\" >0.9451</td>\n",
       "      <td id=\"T_0ac35_row4_col5\" class=\"data row4 col5\" >0.9155</td>\n",
       "      <td id=\"T_0ac35_row4_col6\" class=\"data row4 col6\" >0.9199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0ac35_row5_col0\" class=\"data row5 col0\" >0.9444</td>\n",
       "      <td id=\"T_0ac35_row5_col1\" class=\"data row5 col1\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row5_col2\" class=\"data row5 col2\" >0.9583</td>\n",
       "      <td id=\"T_0ac35_row5_col3\" class=\"data row5 col3\" >0.9537</td>\n",
       "      <td id=\"T_0ac35_row5_col4\" class=\"data row5 col4\" >0.9451</td>\n",
       "      <td id=\"T_0ac35_row5_col5\" class=\"data row5 col5\" >0.9155</td>\n",
       "      <td id=\"T_0ac35_row5_col6\" class=\"data row5 col6\" >0.9199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_0ac35_row6_col0\" class=\"data row6 col0\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row6_col1\" class=\"data row6 col1\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row6_col2\" class=\"data row6 col2\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row6_col4\" class=\"data row6 col4\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row6_col5\" class=\"data row6 col5\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row6_col6\" class=\"data row6 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_0ac35_row7_col0\" class=\"data row7 col0\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row7_col1\" class=\"data row7 col1\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row7_col2\" class=\"data row7 col2\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row7_col4\" class=\"data row7 col4\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row7_col5\" class=\"data row7 col5\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row7_col6\" class=\"data row7 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_0ac35_row8_col0\" class=\"data row8 col0\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row8_col1\" class=\"data row8 col1\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row8_col2\" class=\"data row8 col2\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row8_col4\" class=\"data row8 col4\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row8_col5\" class=\"data row8 col5\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row8_col6\" class=\"data row8 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_0ac35_row9_col0\" class=\"data row9 col0\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row9_col1\" class=\"data row9 col1\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row9_col4\" class=\"data row9 col4\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row9_col5\" class=\"data row9 col5\" >1.0000</td>\n",
       "      <td id=\"T_0ac35_row9_col6\" class=\"data row9 col6\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_0ac35_row10_col0\" class=\"data row10 col0\" >0.9567</td>\n",
       "      <td id=\"T_0ac35_row10_col1\" class=\"data row10 col1\" >0.9899</td>\n",
       "      <td id=\"T_0ac35_row10_col2\" class=\"data row10 col2\" >0.9617</td>\n",
       "      <td id=\"T_0ac35_row10_col3\" class=\"data row10 col3\" >0.9600</td>\n",
       "      <td id=\"T_0ac35_row10_col4\" class=\"data row10 col4\" >0.9569</td>\n",
       "      <td id=\"T_0ac35_row10_col5\" class=\"data row10 col5\" >0.9325</td>\n",
       "      <td id=\"T_0ac35_row10_col6\" class=\"data row10 col6\" >0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ac35_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_0ac35_row11_col0\" class=\"data row11 col0\" >0.0405</td>\n",
       "      <td id=\"T_0ac35_row11_col1\" class=\"data row11 col1\" >0.0184</td>\n",
       "      <td id=\"T_0ac35_row11_col2\" class=\"data row11 col2\" >0.0384</td>\n",
       "      <td id=\"T_0ac35_row11_col3\" class=\"data row11 col3\" >0.0398</td>\n",
       "      <td id=\"T_0ac35_row11_col4\" class=\"data row11 col4\" >0.0405</td>\n",
       "      <td id=\"T_0ac35_row11_col5\" class=\"data row11 col5\" >0.0640</td>\n",
       "      <td id=\"T_0ac35_row11_col6\" class=\"data row11 col6\" >0.0636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe30871dc40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lda',\n",
       "                              LinearDiscriminantAnalysis(n_components=None,\n",
       "                                                         priors=None,\n",
       "                                                         shrinkage=0.2,\n",
       "                                                         solver='lsqr',\n",
       "                                                         store_covariance=False,\n",
       "                                                         tol=0.0001)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=7.898000000000001,\n",
       "                                                 class_weight={}, dual=False,\n",
       "                                                 fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=1000,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_sta...\n",
       "                                             importance_type='split',\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=20,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=100, n_jobs=-1,\n",
       "                                             num_leaves=31, objective=None,\n",
       "                                             random_state=42, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=1.0,\n",
       "                                             subsample_for_bin=200000,\n",
       "                                             subsample_freq=0))],\n",
       "                 flatten_transform=True, n_jobs=-1, verbose=False,\n",
       "                 voting='soft', weights=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#개별 model 생성\n",
    "model_et = create_model('et', fold = 5)\n",
    "model_lr = create_model('lr', fold = 5)\n",
    "model_rf = create_model('rf', fold = 5)\n",
    "model_lda = create_model('lda', fold = 5)\n",
    "model_lightgbm = create_model('lightgbm', fold = 5)\n",
    "\n",
    "#model tuning\n",
    "tuned_lr = tune_model(model_lr, fold=5, optimize = 'F1', choose_better = True)\n",
    "tuned_lda = tune_model(model_lda, fold=5, optimize = 'F1', choose_better = True)\n",
    "tuned_rf = tune_model(model_rf, fold=5, optimize = 'F1', choose_better = True)\n",
    "tuned_et = tune_model(model_et, fold=5, optimize = 'F1', choose_better = True)\n",
    "tuned_lightgbm = tune_model(model_lightgbm, fold=5, optimize = 'F1', choose_better = True)\n",
    "\n",
    "#model ensemble\n",
    "blend_models = blend_models(estimator_list = [tuned_lda,tuned_lr,tuned_et,tuned_rf,tuned_lightgbm], optimize = 'F1')\n",
    "blend_models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "75d523d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model 성능 확인1\n",
    "plot_model(blend_models, plot='learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b6f4a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 [0.966, 0.986]\n",
      "model2: [0.961, 0.986]\n",
      "model3: [0.981, 0.971]\n",
      "model4: [1.0, 0.971]\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/minwoo/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "#model 성능 확인2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "xtrain = dfx.iloc[:len(train),:]\n",
    "xtest = dfx.iloc[len(train):,:]\n",
    "ytrain = dfy.iloc[:len(train)]\n",
    "class_le = preprocessing.LabelEncoder()\n",
    "ytrain = class_le.fit_transform(train['class'])\n",
    "\n",
    "scale = StandardScaler().fit(xtrain)\n",
    "xtrain_scaled = scale.transform(xtrain)\n",
    "xtest_scaled = scale.transform(xtest)\n",
    "x_train, x_test, y_train, y_test = train_test_split(xtrain_scaled, ytrain, test_size=0.25)\n",
    "\n",
    "def get_scores(model, xtrain, xtest, ytrain, ytest):\n",
    "    ypred1 = model.predict(xtrain)\n",
    "    ypred2 = model.predict(xtest)\n",
    "    A = f1_score(ytrain, ypred1, average='macro')\n",
    "    B = f1_score(ytest, ypred2, average='macro')\n",
    "    return [round(A,3), round(B,3)]\n",
    "\n",
    "def make_models(xtrain, xtest, ytrain, ytest):\n",
    "    model1 = LogisticRegression(solver='liblinear',penalty='l1', random_state=0).fit(x_train, y_train)\n",
    "    print('model1', get_scores(model1, x_train, x_test, y_train, y_test))\n",
    "\n",
    "    model2 = RandomForestClassifier(min_samples_split=2,max_depth=7,max_leaf_nodes=11,n_estimators=125,random_state=0).fit(x_train, y_train)  #max_depth, learning_rate 활용\n",
    "    print('model2:', get_scores(model2, x_train, x_test, y_train, y_test)) \n",
    "    \n",
    "    model3 = ExtraTreesClassifier(min_samples_split=11,max_depth=6,n_estimators=118,random_state=0).fit(x_train, y_train)  #max_depth, learning_rate 활용\n",
    "    print('model3:', get_scores(model3, x_train, x_test, y_train, y_test)) \n",
    "    \n",
    "    model4 = blend_models.fit(x_train, y_train) \n",
    "    print('model4:', get_scores(model4, x_train, x_test, y_train, y_test)) \n",
    "    \n",
    "make_models(x_train, x_test, y_train ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "030e2b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      A\n",
       "1      B\n",
       "2      C\n",
       "3      C\n",
       "4      A\n",
       "      ..\n",
       "170    B\n",
       "171    C\n",
       "172    C\n",
       "173    B\n",
       "174    B\n",
       "Name: class, Length: 175, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#생성 model 기반 class 분류 예측\n",
    "final_model = finalize_model(blend_models)\n",
    "predict_final = predict_model(final_model, data=xsubmission)\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['class'] = class_le.inverse_transform(predict_final['Label'])\n",
    "submit.to_csv('./submit.csv', index=False)\n",
    "submit['class'] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
